---
title: "High Performance Computing in R, without rewriting your code"
author: "David Mawdsley &  Pen Richardson"
date: "6 November 2017<p><img src='http://assets.manchester.ac.uk/logos/hi-res/TAB_UNI_MAIN_logo/White_backgrounds/TAB_col_white_background.png' style='border:0px solid black' width='50%'></p>"
output: 
  revealjs::revealjs_presentation:
    transition: fade
    theme: solarize
    fig_height: 6
    self_contained: true
    reveal_options:
      controls: false
---

## Introduction
```{r setup, echo = FALSE, messages = FALSE}

suppressMessages(library("tidyverse"))
suppressMessages(library("stringr"))
```

[](Key message - waiting for code to run is a pain.  How do we 
make it quicker?)

* Waiting for your R code to run is a pain
* We're going to talk about ways to make it faster
    * Without editing your code

* Two approaches:
  	* Faster R
	* HPC at UoM

## Optimising code

* Problem specific
* Profiling is a good starting point
	  * [Built into R studio](https://rstudio.github.io/profvis/)

## 

![][Profile1]

[Profile1]: Profile1.png

##

![][Profile2]

[Profile2]: Profile2.png

##  Optimising *how* your code runs

* Most PCs have 2, 4 or 8 cores.  
  	* R will only use one of these by default
* Two approaches to using more of them:
  	* Explicitly parallise code
		  * Not covering this in this talk
		  
	* *Use a version of R with libraries that use > 1 core*

## Microsoft R Open

* [MS R Open](https://mran.microsoft.com/open/) uses optimised versions of
  [BLAS and LAPACK](https://software.intel.com/en-us/mkl).
  	* Typically quicker even on a single thread
	* (Usually) even quicker if we use multiple threads
* Speed up will depend on _what_ you're doing
  	* Linear algebra 

## Benchmarking R

Used the Revobenchmark in the [version.compare](https://github.com/andrie/version.compare) package:

  * Matrix multiplication 
  * Cholesky factorisation
  * QR Decomposition
  * Singular value decomposition
  * PCA
  * Linear Discriminant Analysis 

## 

```{r, echo = FALSE}
source("testthreads/loadJobStats.R")

LaptopResults <- bind_rows(loadJobStats("testthreads/LaptopLinuxMSR.rda"),
                        loadJobStats("testthreads/LaptopLinuxStandardR.rda"))

symboffset <- 16
provlevels <- 16:(length(levels(LaptopResults$RProvider)) + symboffset - 1)
names(provlevels) <- levels(LaptopResults$RProvider)
# ggplot(LaptopResults, aes(x = threads, y = time, colour = task)) + geom_point() + 

#   geom_line() + facet_wrap(~ infile) 
```


```{r, echo = FALSE, message = FALSE}

LaptopResults %>% filter(RProvider != "Microsoft") %>% 
  ggplot(aes(x = quasithread, y = time, colour = task, shape = RProvider, label = RProvider)) + geom_point() + geom_line() + 
  coord_cartesian(xlim = c(0, 4), ylim=c(0,65)) +
  scale_shape_manual(values = provlevels) +
  scale_x_continuous(breaks = 1:4) + 
  labs(x = "Threads", y = "Time (seconds)",  colour = "Task",
       title = "Laptop; standard vs MSR")
```

##

```{r, echo = FALSE}


LaptopResults %>%
  ggplot(aes(x = quasithread, y = time, colour = task, shape = RProvider, label = RProvider)) + geom_point() + geom_line() + 
  coord_cartesian(xlim = c(0, 4), ylim=c(0,65)) +
  scale_shape_manual(values = provlevels) +
  scale_x_continuous(breaks = 1:4) + 
  labs(x = "Threads", y = "Time (seconds)",  colour = "Task",
       title = "Laptop; standard vs MSR")
```

## 

```{r, echo = FALSE}
Basetimes <- LaptopResults %>% 
  filter(RProvider != "Microsoft") %>%
  rename(basetime = time) %>% 
  select(task, basetime)

LaptopResults %>% 
  filter(RProvider == "Microsoft") %>% 
  inner_join(Basetimes, by = "task") %>% 
  mutate(speedup = basetime / time)  %>% 
  ggplot(aes(x = threads, y=speedup, colour=task)) + geom_point() + geom_line() +
  labs(x = "Threads", y = "Speedup wrt standard R",  colour = "Task",
       title = "Laptop; speedup over standard R") + geom_hline(aes(yintercept = 1))
  
```

## Compatibility between standard R and Microsoft R open

* Version lags (slightly) behind standard R
* ["100% compatible with"](https://mran.microsoft.com/open/) standard R
* Uses its own version of [CRAN](https://cran.r-project.org/); MRAN
  	* Frozen snapshot  of CRAN for each release of MS R Open
	* Can install CRAN packages with `repos="URL"` option
	* `checkpoint` library lets you use packages at arbitrary snapshot dates

## What if this isn't enough?

![][jaws]

[jaws]: https://forums.unrealengine.com/attachment.php?attachmentid=27895&d=1425367123 "Jaws"

## The CSF

* [George Leaver talked about the iCSF in March](http://ri.itservices.manchester.ac.uk/course/herc/icsf.pdf)
  	* Interactive facility
* We'll focus on the [CSF](http://ri.itservices.manchester.ac.uk/csf/)
  	* "Traditional" batch system
	* Write a job script, submit it, wait for it to run
* Aimed at research groups who have contributed to it
  	* Limited free at the point of use availability
* Has [several versions of standard R and MS R Open](http://ri.itservices.manchester.ac.uk/csf-apps/software/applications/r/) installed.

## Getting started on the CSF

* [Applying for an account](http://ri.itservices.manchester.ac.uk/csf/getting-started-on-the-csf/user-account/)
* [Training course](http://www.staffnet.manchester.ac.uk/staff-learning-and-development/academicandresearch/practical-skills-and-knowledge/it-skills/research-computing/research-courses/)


* Demonstrations:
  	1. [Running a job](http://ri.itservices.manchester.ac.uk/userdocs/sge/tutorial/) on multiple cores
	2. Running the same job many times ([job arrays](http://ri.itservices.manchester.ac.uk/userdocs/sge/job-arrays/))


## 

```{r, echo = FALSE, warning = FALSE}

allResults <- bind_rows(
                        loadJobStats("./testthreads/csfIvybridge.rda"),
                         loadJobStats("./testthreads/csfSandybridge.rda"),
                         loadJobStats("./testthreads/csfHaswell.rda"),
                         loadJobStats("./testthreads/csfBroadwell.rda"),
                         loadJobStats("./testthreads/csfWestmere.rda"),
                        
                        loadJobStats("./testthreads/csfBaseR/csfIvybridge.rda"),
                         loadJobStats("./testthreads/csfBaseR/csfSandybridge.rda"),
                         loadJobStats("./testthreads/csfBaseR/csfHaswell.rda"),
                         loadJobStats("./testthreads/csfBaseR/csfBroadwell.rda"),
                         loadJobStats("./testthreads/csfBaseR/csfWestmere.rda")
                        )

allResults %>%  filter(infile == "csfSandybridge.rda") %>% 
  filter(quasithread <= 8) %>% 
  ggplot(aes(x = quasithread, y = time, colour = task, shape = RProvider)) + geom_point() + 
  geom_line() + facet_wrap(~ infile) + scale_x_continuous(limits = c(0,12), breaks = 1:12) +
  scale_y_continuous(limits = c(0,60)) + 
  labs(x = "Threads", y = "Time (seconds)",  colour = "Task",
       title = "CSF performance")

```

##


```{r, echo = FALSE, warning = FALSE}
allResults %>%  filter(infile == "csfSandybridge.rda") %>% 
  ggplot(aes(x = quasithread, y = time, colour = task, shape = RProvider)) + geom_point() + 
  geom_line() + facet_wrap(~ infile) +
  scale_y_continuous(limits = c(0,60)) + 
  scale_x_continuous(breaks = 1:12) + 
  labs(x = "Threads", y = "Time (seconds)",  colour = "Task",
       title = "CSF performance")

```

##

```{r, echo = FALSE}

CSFBasetimes <- allResults %>% 
  filter(RProvider != "Microsoft") %>%
  rename(basetime = time) %>% 
  select(task, basetime,infile)

allResults %>%  filter(infile == "csfSandybridge.rda") %>% 
  filter(RProvider == "Microsoft") %>% 
  inner_join(CSFBasetimes, by = c("task", "infile")) %>% 
  mutate(speedup = basetime / time)  %>% 
  ggplot(aes(x = threads, y=speedup, colour=task, group = task)) + geom_point() + geom_line() +
  facet_wrap(~ infile) + 
  labs(x = "Threads", y = "Speedup wrt standard R",  colour = "Task",
       title = "CSF; speedup over standard R") +
      coord_cartesian(xlim=c(1,8), ylim = c(0,80)) + geom_hline(aes(yintercept = 1))

```


## Setting the number of threads

* Unclear why performance suffers if all cores used
    * Little benefit in > 8 cores 
    * Less queuing time; easier to schedule jobs
* Set cores required with
```
#$ -pe smp.pe 8 
```
in your job script
* You *must* include the line:
```
export OMP_NUM_THREADS=$NSLOTS
```
in your job submission script
    

## The parallel library and MS R Open

* Take care not to "double parallise"
  	* Each processes spawned by `parallel` will spawn its own threads
  	* can limit threads used by _each_ process with
  	```
  	setMKLthreads(<n>)
  	```
	* Experimentation will be needed to find the best balance between the two approaches


## Getting help/training

* [Research IT training courses](http://www.staffnet.manchester.ac.uk/staff-learning-and-development/academicandresearch/practical-skills-and-knowledge/it-skills/research-computing/research-courses/)
  	* Next CSF course 20 November.
    * Next R courses 28 November and 5 December
	  * Courses on Unix shell and Makefiles may also be of interest

* Feel free to get in touch directly, or via the [Research IT request form](http://www.itservices.manchester.ac.uk/research/support/)
  	* david.mawdsley@manchester.ac.uk
  	* pen.richardson@manchester.ac.uk

* These slides are availabile at [https://mawds.github.io/RUGCSF/RUGCSF.html](https://mawds.github.io/RUGCSF/RUGCSF.html)
  	
## Conclusions

* Switching over to MS R Open can offer big speedups
  	* No modification of code needed
	  * Though some care needed with package versions
* The CSF is ideal for
    * bigger jobs
    * repeated jobs
* Important to set the number of threads correctly
